{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.optim import SGD\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Download dữ liệu CIFAR10 sau đó chia thành 2 tập dữ liệu train và validation.\n",
    "+ Chuẩn hóa dữ liệu với mean = 0.5 và std = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 65536/170498071 [00:00<35:13, 80627.59it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor(), transforms\u001b[38;5;241m.\u001b[39mNormalize(mean \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.5\u001b[39m, ), std \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.5\u001b[39m, ))])\n\u001b[0;32m----> 6\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCIFAR10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m testset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Downloads/DecisionTree_RandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/site-packages/torchvision/datasets/cifar.py:66\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/site-packages/torchvision/datasets/cifar.py:140\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/site-packages/torchvision/datasets/utils.py:395\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    393\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 395\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/site-packages/torchvision/datasets/utils.py:132\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 132\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/site-packages/torchvision/datasets/utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     31\u001b[0m             fh\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     32\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/LEARN/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean = (0.5, ), std = (0.5, ))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='CIFAR10', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1024, num_workers=8, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='D:/Downloads/DecisionTree_RandomForest', train=True, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Hiển thị 5 ảnh đầu tiên trong tập dữ liệu testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img * 0.5 + 0.5\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "for i, (images, labels) in enumerate(trainloader, 0):\n",
    "  imshow(torchvision.utils.make_grid(images[:8]))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Xây dựng model MLP cơ bản để train tập dữ liệu CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(n_features):\n",
    "  model = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(n_features, 256),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(256, 10)\n",
    "  ).to(device)\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Khởi tạo hàm loss function và phương thức optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 32*32 \n",
    "model = getModel(n_features)\n",
    "lr = 0.01\n",
    "optim = SGD(params = model.parameters(), lr = lr)\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Xây dựng hàm đánh giá model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, testloader, criterion):\n",
    "  model.eval()\n",
    "  test_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for images, labels in testloader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      test_loss += loss.item()\n",
    "      \n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  test_loss = test_loss / len(testloader)\n",
    "  return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Bắt đầu training và đánh giá model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m running_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrainloader\u001b[49m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     13\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# khởi tạo giá trị đạo hàm = 0\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optim.zero_grad() # khởi tạo giá trị đạo hàm = 0\n",
    "\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 2 dòng dưới đây là lan truyền ngược và optimizer tham số w và b.\n",
    "        loss.backward()\n",
    "        optim.step()        \n",
    "\n",
    "    epoch_accuracy = 100 * running_correct / total\n",
    "    epoch_loss = running_loss / (i + 1)\n",
    "    test_loss, test_accuracy = evaluate(model, testloader, loss_fn)\n",
    "    print(f\"Epoch [{epoch + 1}/{n_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    \n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 5))\n",
    "plt.subplot(121)\n",
    "plt.title('Loss Epochs')\n",
    "plt.plot(train_losses, label = 'Train Loss')\n",
    "plt.plot(test_losses, label = 'Test Loss')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.title('Accuracy Epoch')\n",
    "plt.plot(test_accuracies, label = 'Test Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dưới đây là bài tập về code from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zScoreScaling(tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxScaling(tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.]])\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [1.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([\n",
    "    [1.0, 2.0, 3.0], \n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]\n",
    "])\n",
    "zscore = zScoreScaling(tensor)\n",
    "min_max = minMaxScaling(tensor)\n",
    "print(zscore)\n",
    "print(min_max)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "linear = Linear(3, 2)\n",
    "out = linear.forward(tensor)\n",
    "print(out)\n",
    "print(f\"Weight = {linear.weight}\")\n",
    "print(f\"Bias = {linear.bias}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "LEARN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
